bf16: false
dataset_text_field: text
eval_steps: 1
eval_strategy: epoch
evaluation_strategy: epoch
gradient_accumulation_steps: 2
greater_is_better: false
group_by_length: true
learning_rate: 2.0e-05
load_best_model_at_end: true
logging_steps: 25
lr_scheduler_type: cosine
max_grad_norm: 0.15
max_seq_length: 1000
max_steps: -1
metric_for_best_model: eval_loss
num_train_epochs: 1
optim: paged_adamw_32bit
output_dir: logs
per_device_train_batch_size: 1
report_to: none
save_steps: 0
save_strategy: epoch
warmup_ratio: 0.1
weight_decay: 0.123
