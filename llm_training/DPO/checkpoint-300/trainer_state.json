{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 3.0,
  "eval_steps": 500,
  "global_step": 300,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.1,
      "grad_norm": 114.32610321044922,
      "learning_rate": 9.666666666666666e-07,
      "logits/chosen": -2.771484375,
      "logits/rejected": -2.859375,
      "logps/chosen": -266.25,
      "logps/rejected": -257.0,
      "loss": 0.6953,
      "rewards/accuracies": 0.20000000298023224,
      "rewards/chosen": -0.00624847412109375,
      "rewards/margins": -0.004375457763671875,
      "rewards/rejected": -0.0018749237060546875,
      "step": 10
    },
    {
      "epoch": 0.2,
      "grad_norm": 78.66477966308594,
      "learning_rate": 9.333333333333333e-07,
      "logits/chosen": -2.984375,
      "logits/rejected": -2.94140625,
      "logps/chosen": -166.875,
      "logps/rejected": -223.375,
      "loss": 0.6926,
      "rewards/accuracies": 0.20000000298023224,
      "rewards/chosen": -0.003124237060546875,
      "rewards/margins": 0.0012493133544921875,
      "rewards/rejected": -0.004375457763671875,
      "step": 20
    },
    {
      "epoch": 0.3,
      "grad_norm": 30.47642707824707,
      "learning_rate": 9e-07,
      "logits/chosen": -2.91796875,
      "logits/rejected": -2.884765625,
      "logps/chosen": -295.75,
      "logps/rejected": -152.625,
      "loss": 0.6935,
      "rewards/accuracies": 0.30000001192092896,
      "rewards/chosen": -1.1920928955078125e-07,
      "rewards/margins": -0.00023436546325683594,
      "rewards/rejected": 0.00023436546325683594,
      "step": 30
    },
    {
      "epoch": 0.4,
      "grad_norm": 78.59605407714844,
      "learning_rate": 8.666666666666667e-07,
      "logits/chosen": -2.865234375,
      "logits/rejected": -3.001953125,
      "logps/chosen": -455.5,
      "logps/rejected": -329.5,
      "loss": 0.6944,
      "rewards/accuracies": 0.20000000298023224,
      "rewards/chosen": -0.0018749237060546875,
      "rewards/margins": -0.002655029296875,
      "rewards/rejected": 0.0007810592651367188,
      "step": 40
    },
    {
      "epoch": 0.5,
      "grad_norm": 84.6889877319336,
      "learning_rate": 8.333333333333333e-07,
      "logits/chosen": -2.783203125,
      "logits/rejected": -2.783203125,
      "logps/chosen": -360.75,
      "logps/rejected": -285.25,
      "loss": 0.6953,
      "rewards/accuracies": 0.10000000149011612,
      "rewards/chosen": -0.004840850830078125,
      "rewards/margins": -0.0045318603515625,
      "rewards/rejected": -0.0003123283386230469,
      "step": 50
    },
    {
      "epoch": 0.6,
      "grad_norm": 126.72489166259766,
      "learning_rate": 8e-07,
      "logits/chosen": -2.826171875,
      "logits/rejected": -2.8046875,
      "logps/chosen": -389.0,
      "logps/rejected": -427.75,
      "loss": 0.6896,
      "rewards/accuracies": 0.30000001192092896,
      "rewards/chosen": -0.002498626708984375,
      "rewards/margins": 0.00687408447265625,
      "rewards/rejected": -0.009368896484375,
      "step": 60
    },
    {
      "epoch": 0.7,
      "grad_norm": 98.53165435791016,
      "learning_rate": 7.666666666666667e-07,
      "logits/chosen": -2.84375,
      "logits/rejected": -2.837890625,
      "logps/chosen": -292.0,
      "logps/rejected": -299.75,
      "loss": 0.6883,
      "rewards/accuracies": 0.6000000238418579,
      "rewards/chosen": 0.0036716461181640625,
      "rewards/margins": 0.007415771484375,
      "rewards/rejected": -0.003749847412109375,
      "step": 70
    },
    {
      "epoch": 0.8,
      "grad_norm": 64.13279724121094,
      "learning_rate": 7.333333333333332e-07,
      "logits/chosen": -2.728515625,
      "logits/rejected": -2.75390625,
      "logps/chosen": -289.75,
      "logps/rejected": -236.875,
      "loss": 0.692,
      "rewards/accuracies": 0.4000000059604645,
      "rewards/chosen": -0.0006246566772460938,
      "rewards/margins": 0.0032787322998046875,
      "rewards/rejected": -0.00390625,
      "step": 80
    },
    {
      "epoch": 0.9,
      "grad_norm": 70.78516387939453,
      "learning_rate": 7e-07,
      "logits/chosen": -2.904296875,
      "logits/rejected": -2.7734375,
      "logps/chosen": -220.625,
      "logps/rejected": -294.0,
      "loss": 0.6908,
      "rewards/accuracies": 0.4000000059604645,
      "rewards/chosen": -0.003749847412109375,
      "rewards/margins": 0.0023403167724609375,
      "rewards/rejected": -0.006092071533203125,
      "step": 90
    },
    {
      "epoch": 1.0,
      "grad_norm": 143.18150329589844,
      "learning_rate": 6.666666666666666e-07,
      "logits/chosen": -2.966796875,
      "logits/rejected": -2.876953125,
      "logps/chosen": -311.5,
      "logps/rejected": -312.0,
      "loss": 0.6881,
      "rewards/accuracies": 0.30000001192092896,
      "rewards/chosen": -0.004375457763671875,
      "rewards/margins": 0.00562286376953125,
      "rewards/rejected": -0.0099945068359375,
      "step": 100
    },
    {
      "epoch": 1.1,
      "grad_norm": 86.17542266845703,
      "learning_rate": 6.333333333333332e-07,
      "logits/chosen": -2.9296875,
      "logits/rejected": -2.8984375,
      "logps/chosen": -296.5,
      "logps/rejected": -307.5,
      "loss": 0.6702,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": 0.0184326171875,
      "rewards/margins": 0.04638671875,
      "rewards/rejected": -0.0279693603515625,
      "step": 110
    },
    {
      "epoch": 1.2,
      "grad_norm": 78.39983367919922,
      "learning_rate": 6e-07,
      "logits/chosen": -2.81640625,
      "logits/rejected": -2.64453125,
      "logps/chosen": -340.0,
      "logps/rejected": -189.5,
      "loss": 0.6705,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.0203857421875,
      "rewards/margins": 0.042724609375,
      "rewards/rejected": -0.0223388671875,
      "step": 120
    },
    {
      "epoch": 1.3,
      "grad_norm": 35.68317794799805,
      "learning_rate": 5.666666666666666e-07,
      "logits/chosen": -2.71875,
      "logits/rejected": -2.791015625,
      "logps/chosen": -300.0,
      "logps/rejected": -317.0,
      "loss": 0.6675,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.0254669189453125,
      "rewards/margins": 0.061065673828125,
      "rewards/rejected": -0.035614013671875,
      "step": 130
    },
    {
      "epoch": 1.4,
      "grad_norm": 91.619140625,
      "learning_rate": 5.333333333333333e-07,
      "logits/chosen": -2.818359375,
      "logits/rejected": -2.91796875,
      "logps/chosen": -314.5,
      "logps/rejected": -325.75,
      "loss": 0.6547,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.033111572265625,
      "rewards/margins": 0.07623291015625,
      "rewards/rejected": -0.043121337890625,
      "step": 140
    },
    {
      "epoch": 1.5,
      "grad_norm": 61.61646270751953,
      "learning_rate": 5e-07,
      "logits/chosen": -2.8515625,
      "logits/rejected": -2.884765625,
      "logps/chosen": -257.5,
      "logps/rejected": -224.5,
      "loss": 0.6691,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": 0.0218658447265625,
      "rewards/margins": 0.04998779296875,
      "rewards/rejected": -0.0281219482421875,
      "step": 150
    },
    {
      "epoch": 1.6,
      "grad_norm": 56.34579086303711,
      "learning_rate": 4.6666666666666666e-07,
      "logits/chosen": -2.79296875,
      "logits/rejected": -2.873046875,
      "logps/chosen": -303.25,
      "logps/rejected": -219.625,
      "loss": 0.6713,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": 0.0162506103515625,
      "rewards/margins": 0.043121337890625,
      "rewards/rejected": -0.0268707275390625,
      "step": 160
    },
    {
      "epoch": 1.7,
      "grad_norm": 74.92948913574219,
      "learning_rate": 4.3333333333333335e-07,
      "logits/chosen": -2.9609375,
      "logits/rejected": -2.849609375,
      "logps/chosen": -292.75,
      "logps/rejected": -308.25,
      "loss": 0.6612,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.0243682861328125,
      "rewards/margins": 0.0653076171875,
      "rewards/rejected": -0.040924072265625,
      "step": 170
    },
    {
      "epoch": 1.8,
      "grad_norm": 95.20320892333984,
      "learning_rate": 4e-07,
      "logits/chosen": -2.958984375,
      "logits/rejected": -3.0,
      "logps/chosen": -390.0,
      "logps/rejected": -400.75,
      "loss": 0.6642,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": 0.021942138671875,
      "rewards/margins": 0.05914306640625,
      "rewards/rejected": -0.03717041015625,
      "step": 180
    },
    {
      "epoch": 1.9,
      "grad_norm": 58.343441009521484,
      "learning_rate": 3.666666666666666e-07,
      "logits/chosen": -2.9765625,
      "logits/rejected": -2.951171875,
      "logps/chosen": -286.0,
      "logps/rejected": -268.0,
      "loss": 0.671,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": 0.01328277587890625,
      "rewards/margins": 0.04522705078125,
      "rewards/rejected": -0.031951904296875,
      "step": 190
    },
    {
      "epoch": 2.0,
      "grad_norm": 129.5679931640625,
      "learning_rate": 3.333333333333333e-07,
      "logits/chosen": -2.76953125,
      "logits/rejected": -2.708984375,
      "logps/chosen": -265.25,
      "logps/rejected": -260.5,
      "loss": 0.6682,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.005939483642578125,
      "rewards/margins": 0.049530029296875,
      "rewards/rejected": -0.0435791015625,
      "step": 200
    },
    {
      "epoch": 2.1,
      "grad_norm": 91.1841049194336,
      "learning_rate": 3e-07,
      "logits/chosen": -2.87890625,
      "logits/rejected": -2.9453125,
      "logps/chosen": -221.5,
      "logps/rejected": -203.375,
      "loss": 0.6603,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.023895263671875,
      "rewards/margins": 0.0660400390625,
      "rewards/rejected": -0.04217529296875,
      "step": 210
    },
    {
      "epoch": 2.2,
      "grad_norm": 79.18795013427734,
      "learning_rate": 2.6666666666666667e-07,
      "logits/chosen": -3.001953125,
      "logits/rejected": -2.892578125,
      "logps/chosen": -227.75,
      "logps/rejected": -259.25,
      "loss": 0.6589,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.021240234375,
      "rewards/margins": 0.0693359375,
      "rewards/rejected": -0.048126220703125,
      "step": 220
    },
    {
      "epoch": 2.3,
      "grad_norm": 76.41929626464844,
      "learning_rate": 2.3333333333333333e-07,
      "logits/chosen": -2.935546875,
      "logits/rejected": -2.912109375,
      "logps/chosen": -293.25,
      "logps/rejected": -229.75,
      "loss": 0.65,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.03717041015625,
      "rewards/margins": 0.08905029296875,
      "rewards/rejected": -0.0518798828125,
      "step": 230
    },
    {
      "epoch": 2.4,
      "grad_norm": 93.5716323852539,
      "learning_rate": 2e-07,
      "logits/chosen": -2.8515625,
      "logits/rejected": -2.880859375,
      "logps/chosen": -416.0,
      "logps/rejected": -418.25,
      "loss": 0.6411,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.038116455078125,
      "rewards/margins": 0.10748291015625,
      "rewards/rejected": -0.06939697265625,
      "step": 240
    },
    {
      "epoch": 2.5,
      "grad_norm": 146.0907440185547,
      "learning_rate": 1.6666666666666665e-07,
      "logits/chosen": -2.865234375,
      "logits/rejected": -2.765625,
      "logps/chosen": -291.75,
      "logps/rejected": -433.75,
      "loss": 0.6511,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.014373779296875,
      "rewards/margins": 0.079345703125,
      "rewards/rejected": -0.06500244140625,
      "step": 250
    },
    {
      "epoch": 2.6,
      "grad_norm": 58.304420471191406,
      "learning_rate": 1.3333333333333334e-07,
      "logits/chosen": -2.8671875,
      "logits/rejected": -2.939453125,
      "logps/chosen": -350.25,
      "logps/rejected": -217.25,
      "loss": 0.6476,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.048736572265625,
      "rewards/margins": 0.09686279296875,
      "rewards/rejected": -0.048126220703125,
      "step": 260
    },
    {
      "epoch": 2.7,
      "grad_norm": 119.74332427978516,
      "learning_rate": 1e-07,
      "logits/chosen": -2.72265625,
      "logits/rejected": -2.77734375,
      "logps/chosen": -430.0,
      "logps/rejected": -316.0,
      "loss": 0.6479,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.046173095703125,
      "rewards/margins": 0.0963134765625,
      "rewards/rejected": -0.050140380859375,
      "step": 270
    },
    {
      "epoch": 2.8,
      "grad_norm": 186.56832885742188,
      "learning_rate": 6.666666666666667e-08,
      "logits/chosen": -2.943359375,
      "logits/rejected": -2.896484375,
      "logps/chosen": -323.5,
      "logps/rejected": -222.0,
      "loss": 0.6535,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.048431396484375,
      "rewards/margins": 0.0848388671875,
      "rewards/rejected": -0.036407470703125,
      "step": 280
    },
    {
      "epoch": 2.9,
      "grad_norm": 37.735496520996094,
      "learning_rate": 3.3333333333333334e-08,
      "logits/chosen": -2.716796875,
      "logits/rejected": -2.615234375,
      "logps/chosen": -262.0,
      "logps/rejected": -301.75,
      "loss": 0.6473,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.0301513671875,
      "rewards/margins": 0.095458984375,
      "rewards/rejected": -0.0653076171875,
      "step": 290
    },
    {
      "epoch": 3.0,
      "grad_norm": 0.0727839395403862,
      "learning_rate": 0.0,
      "logits/chosen": -2.81640625,
      "logits/rejected": -2.89453125,
      "logps/chosen": -228.0,
      "logps/rejected": -221.875,
      "loss": 0.6591,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": 0.0229644775390625,
      "rewards/margins": 0.06689453125,
      "rewards/rejected": -0.043914794921875,
      "step": 300
    }
  ],
  "logging_steps": 10,
  "max_steps": 300,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 0.0,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
